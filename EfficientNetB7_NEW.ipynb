{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS6d_eux_upF",
        "outputId": "1c95238b-c1a0-4eae-fd2e-dfd3392ca260"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JqZBkD4AMbq"
      },
      "outputs": [],
      "source": [
        "# Define the directories for source images and where to move them\n",
        "source_dir = '/content/drive/MyDrive/Processed_IMG_NEW'\n",
        "processed_dir = '/content/drive/MyDrive/Processed_IMG_NEW'\n",
        "\n",
        "\n",
        "# Create train and test directories\n",
        "train_dir = '/content/drive/MyDrive/Processed_IMG_NEW/train'\n",
        "test_dir = '/content/drive/MyDrive/Processed_IMG_NEW/test'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "batch size = 16 , epcohs = 25"
      ],
      "metadata": {
        "id": "l2faT8A4wR_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Set seed for reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Image dimensions and batch size\n",
        "IMG_HEIGHT = 299\n",
        "IMG_WIDTH = 299\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 25\n",
        "PATIENCE = 15\n",
        "\n",
        "# Image data generators with augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    brightness_range=[0.6, 1.4]\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Data generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Compute class weights to handle class imbalance\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_generator.classes),\n",
        "    y=train_generator.classes\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# Load EfficientNetB7 model\n",
        "base_model = tf.keras.applications.EfficientNetB7(\n",
        "    weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
        ")\n",
        "\n",
        "# Unfreeze all layers in the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Custom layers on top of EfficientNetB7\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(3, activation='softmax')  # Adjust the number of classes accordingly\n",
        "])\n",
        "\n",
        "# Focal loss implementation\n",
        "def focal_loss(gamma=2., alpha=0.25):\n",
        "    cce = tf.keras.losses.CategoricalCrossentropy()\n",
        "    def loss(y_true, y_pred):\n",
        "        cce_loss = cce(y_true, y_pred)\n",
        "        p_t = tf.reduce_sum(y_true * y_pred, axis=-1)\n",
        "        modulating_factor = tf.pow(1.0 - p_t, gamma)\n",
        "        alpha_weight_factor = tf.reduce_sum(alpha * y_true, axis=-1)\n",
        "        return modulating_factor * alpha_weight_factor * cce_loss\n",
        "    return loss\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=1e-5),  # Adjusted learning rate for fine-tuning\n",
        "    loss=focal_loss(gamma=2., alpha=0.25),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Learning rate scheduler with warm-up\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 5:\n",
        "        return lr + 1e-5\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "# Callbacks\n",
        "lr_reduction = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss', patience=4, factor=0.3, min_lr=1e-6\n",
        ")\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=PATIENCE, restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=test_generator,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[lr_reduction, early_stopping, lr_scheduler],\n",
        "    class_weight=class_weights,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f\"Final Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Predictions and class-wise metrics\n",
        "y_pred = model.predict(test_generator)\n",
        "y_pred_classes = np.argmax(y_pred, axis=-1)\n",
        "y_true = test_generator.classes\n",
        "\n",
        "# Classification Report\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred_classes, target_names=class_labels))\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
        "print(conf_matrix)\n",
        "\n",
        "# Class-wise Accuracy\n",
        "class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
        "for label, acc in zip(class_labels, class_accuracies):\n",
        "    print(f\"Accuracy for {label}: {acc * 100:.2f}%\")\n",
        "\n",
        "# Save the model\n",
        "model.save(\"efficientnetb7_ad_model.h5\")\n"
      ],
      "metadata": {
        "id": "QeQZMbPXhtFT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "68f0f985-d967-4fa0-9efc-c6fd72215f99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 483 images belonging to 3 classes.\n",
            "Found 207 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5\n",
            "\u001b[1m258076736/258076736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ efficientnetb7 (\u001b[38;5;33mFunctional\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m2560\u001b[0m)        │      \u001b[38;5;34m64,097,687\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2560\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │       \u001b[38;5;34m1,311,232\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │           \u001b[38;5;34m1,539\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ efficientnetb7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2560</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">64,097,687</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2560</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,311,232</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,539</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m65,410,458\u001b[0m (249.52 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,410,458</span> (249.52 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m65,099,731\u001b[0m (248.34 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,099,731</span> (248.34 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m310,727\u001b[0m (1.19 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">310,727</span> (1.19 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m859s\u001b[0m 17s/step - accuracy: 0.3124 - loss: 8.5995 - val_accuracy: 0.3527 - val_loss: 8.3971 - learning_rate: 2.0000e-05\n",
            "Epoch 2/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 977ms/step - accuracy: 0.3623 - loss: 8.2933 - val_accuracy: 0.3285 - val_loss: 8.0198 - learning_rate: 3.0000e-05\n",
            "Epoch 3/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 934ms/step - accuracy: 0.4083 - loss: 7.8796 - val_accuracy: 0.3188 - val_loss: 7.5283 - learning_rate: 4.0000e-05\n",
            "Epoch 4/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 991ms/step - accuracy: 0.3935 - loss: 7.3752 - val_accuracy: 0.3237 - val_loss: 6.9554 - learning_rate: 5.0000e-05\n",
            "Epoch 5/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 955ms/step - accuracy: 0.3845 - loss: 6.7876 - val_accuracy: 0.3140 - val_loss: 6.3241 - learning_rate: 6.0000e-05\n",
            "Epoch 6/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 957ms/step - accuracy: 0.4941 - loss: 6.1538 - val_accuracy: 0.3092 - val_loss: 5.7463 - learning_rate: 6.0000e-05\n",
            "Epoch 7/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.4580 - loss: 5.5887 - val_accuracy: 0.2754 - val_loss: 5.2193 - learning_rate: 6.0000e-05\n",
            "Epoch 8/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 950ms/step - accuracy: 0.4753 - loss: 5.0754 - val_accuracy: 0.3623 - val_loss: 4.7367 - learning_rate: 6.0000e-05\n",
            "Epoch 9/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.5719 - loss: 4.5922 - val_accuracy: 0.3768 - val_loss: 4.2961 - learning_rate: 6.0000e-05\n",
            "Epoch 10/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 952ms/step - accuracy: 0.5770 - loss: 4.1460 - val_accuracy: 0.3575 - val_loss: 3.8993 - learning_rate: 6.0000e-05\n",
            "Epoch 11/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 971ms/step - accuracy: 0.6143 - loss: 3.7444 - val_accuracy: 0.4300 - val_loss: 3.5281 - learning_rate: 6.0000e-05\n",
            "Epoch 12/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 961ms/step - accuracy: 0.7041 - loss: 3.3772 - val_accuracy: 0.4300 - val_loss: 3.1882 - learning_rate: 6.0000e-05\n",
            "Epoch 13/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 983ms/step - accuracy: 0.6231 - loss: 3.0477 - val_accuracy: 0.4541 - val_loss: 2.8853 - learning_rate: 6.0000e-05\n",
            "Epoch 14/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 967ms/step - accuracy: 0.6924 - loss: 2.7409 - val_accuracy: 0.4686 - val_loss: 2.6033 - learning_rate: 6.0000e-05\n",
            "Epoch 15/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 948ms/step - accuracy: 0.7581 - loss: 2.4530 - val_accuracy: 0.4493 - val_loss: 2.3706 - learning_rate: 6.0000e-05\n",
            "Epoch 16/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 970ms/step - accuracy: 0.7350 - loss: 2.2081 - val_accuracy: 0.4638 - val_loss: 2.1289 - learning_rate: 6.0000e-05\n",
            "Epoch 17/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 961ms/step - accuracy: 0.7629 - loss: 1.9770 - val_accuracy: 0.5169 - val_loss: 1.9089 - learning_rate: 6.0000e-05\n",
            "Epoch 18/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 959ms/step - accuracy: 0.7867 - loss: 1.7589 - val_accuracy: 0.5411 - val_loss: 1.7108 - learning_rate: 6.0000e-05\n",
            "Epoch 19/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 963ms/step - accuracy: 0.7948 - loss: 1.5735 - val_accuracy: 0.5604 - val_loss: 1.5198 - learning_rate: 6.0000e-05\n",
            "Epoch 20/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 976ms/step - accuracy: 0.8291 - loss: 1.4019 - val_accuracy: 0.5700 - val_loss: 1.3738 - learning_rate: 6.0000e-05\n",
            "Epoch 21/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 947ms/step - accuracy: 0.7883 - loss: 1.2525 - val_accuracy: 0.6618 - val_loss: 1.1869 - learning_rate: 6.0000e-05\n",
            "Epoch 22/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 937ms/step - accuracy: 0.8449 - loss: 1.1088 - val_accuracy: 0.6957 - val_loss: 1.0517 - learning_rate: 6.0000e-05\n",
            "Epoch 23/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 959ms/step - accuracy: 0.8660 - loss: 0.9820 - val_accuracy: 0.6763 - val_loss: 0.9357 - learning_rate: 6.0000e-05\n",
            "Epoch 24/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 949ms/step - accuracy: 0.8217 - loss: 0.8737 - val_accuracy: 0.7198 - val_loss: 0.8207 - learning_rate: 6.0000e-05\n",
            "Epoch 25/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 955ms/step - accuracy: 0.8667 - loss: 0.7667 - val_accuracy: 0.7391 - val_loss: 0.7254 - learning_rate: 6.0000e-05\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 239ms/step - accuracy: 0.6994 - loss: 0.7428\n",
            "Final Test Accuracy: 0.7391\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          AD       0.85      0.65      0.74        69\n",
            "        EMCI       0.70      0.83      0.76        69\n",
            "        LMCI       0.70      0.74      0.72        69\n",
            "\n",
            "    accuracy                           0.74       207\n",
            "   macro avg       0.75      0.74      0.74       207\n",
            "weighted avg       0.75      0.74      0.74       207\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[45 10 14]\n",
            " [ 4 57  8]\n",
            " [ 4 14 51]]\n",
            "Accuracy for AD: 65.22%\n",
            "Accuracy for EMCI: 82.61%\n",
            "Accuracy for LMCI: 73.91%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "batch size = 16 , epcohs = 50"
      ],
      "metadata": {
        "id": "QzK6n3gDb9HJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Set seed for reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Image dimensions and batch size\n",
        "IMG_HEIGHT = 299\n",
        "IMG_WIDTH = 299\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 50\n",
        "PATIENCE = 15\n",
        "\n",
        "# Image data generators with augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    brightness_range=[0.6, 1.4]\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Data generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Compute class weights to handle class imbalance\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_generator.classes),\n",
        "    y=train_generator.classes\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# Load EfficientNetB7 model\n",
        "base_model = tf.keras.applications.EfficientNetB7(\n",
        "    weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
        ")\n",
        "\n",
        "# Unfreeze all layers in the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Custom layers on top of EfficientNetB7\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(3, activation='softmax')  # Adjust the number of classes accordingly\n",
        "])\n",
        "\n",
        "# Focal loss implementation\n",
        "def focal_loss(gamma=2., alpha=0.25):\n",
        "    cce = tf.keras.losses.CategoricalCrossentropy()\n",
        "    def loss(y_true, y_pred):\n",
        "        cce_loss = cce(y_true, y_pred)\n",
        "        p_t = tf.reduce_sum(y_true * y_pred, axis=-1)\n",
        "        modulating_factor = tf.pow(1.0 - p_t, gamma)\n",
        "        alpha_weight_factor = tf.reduce_sum(alpha * y_true, axis=-1)\n",
        "        return modulating_factor * alpha_weight_factor * cce_loss\n",
        "    return loss\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=1e-5),  # Adjusted learning rate for fine-tuning\n",
        "    loss=focal_loss(gamma=2., alpha=0.25),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Learning rate scheduler with warm-up\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 5:\n",
        "        return lr + 1e-5\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "# Callbacks\n",
        "lr_reduction = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss', patience=4, factor=0.3, min_lr=1e-6\n",
        ")\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=PATIENCE, restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=test_generator,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[lr_reduction, early_stopping, lr_scheduler],\n",
        "    class_weight=class_weights,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f\"Final Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Predictions and class-wise metrics\n",
        "y_pred = model.predict(test_generator)\n",
        "y_pred_classes = np.argmax(y_pred, axis=-1)\n",
        "y_true = test_generator.classes\n",
        "\n",
        "# Classification Report\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred_classes, target_names=class_labels))\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
        "print(conf_matrix)\n",
        "\n",
        "# Class-wise Accuracy\n",
        "class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
        "for label, acc in zip(class_labels, class_accuracies):\n",
        "    print(f\"Accuracy for {label}: {acc * 100:.2f}%\")\n",
        "\n",
        "# Save the model\n",
        "model.save(\"efficientnetb7_ad_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9AuPHHYZQq3C",
        "outputId": "7527125f-0271-4f74-8053-6e9615c5537a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 483 images belonging to 3 classes.\n",
            "Found 207 images belonging to 3 classes.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ efficientnetb7 (\u001b[38;5;33mFunctional\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m2560\u001b[0m)        │      \u001b[38;5;34m64,097,687\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2560\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │       \u001b[38;5;34m1,311,232\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │           \u001b[38;5;34m1,539\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ efficientnetb7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2560</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">64,097,687</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2560</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,311,232</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,539</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m65,410,458\u001b[0m (249.52 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,410,458</span> (249.52 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m65,099,731\u001b[0m (248.34 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,099,731</span> (248.34 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m310,727\u001b[0m (1.19 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">310,727</span> (1.19 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m494s\u001b[0m 7s/step - accuracy: 0.3651 - loss: 8.5931 - val_accuracy: 0.3333 - val_loss: 8.3905 - learning_rate: 2.0000e-05\n",
            "Epoch 2/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 965ms/step - accuracy: 0.3460 - loss: 8.2957 - val_accuracy: 0.3382 - val_loss: 8.0036 - learning_rate: 3.0000e-05\n",
            "Epoch 3/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 945ms/step - accuracy: 0.3904 - loss: 7.8755 - val_accuracy: 0.3527 - val_loss: 7.5160 - learning_rate: 4.0000e-05\n",
            "Epoch 4/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 969ms/step - accuracy: 0.4460 - loss: 7.3570 - val_accuracy: 0.3333 - val_loss: 6.9472 - learning_rate: 5.0000e-05\n",
            "Epoch 5/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 957ms/step - accuracy: 0.4171 - loss: 6.7725 - val_accuracy: 0.3382 - val_loss: 6.3166 - learning_rate: 6.0000e-05\n",
            "Epoch 6/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 960ms/step - accuracy: 0.4299 - loss: 6.1471 - val_accuracy: 0.3527 - val_loss: 5.7370 - learning_rate: 6.0000e-05\n",
            "Epoch 7/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 959ms/step - accuracy: 0.5069 - loss: 5.5781 - val_accuracy: 0.3575 - val_loss: 5.2067 - learning_rate: 6.0000e-05\n",
            "Epoch 8/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 955ms/step - accuracy: 0.5662 - loss: 5.0476 - val_accuracy: 0.3961 - val_loss: 4.7223 - learning_rate: 6.0000e-05\n",
            "Epoch 9/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 978ms/step - accuracy: 0.5558 - loss: 4.5745 - val_accuracy: 0.3382 - val_loss: 4.2830 - learning_rate: 6.0000e-05\n",
            "Epoch 10/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.5767 - loss: 4.1369 - val_accuracy: 0.3237 - val_loss: 3.8823 - learning_rate: 6.0000e-05\n",
            "Epoch 11/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 955ms/step - accuracy: 0.6422 - loss: 3.7264 - val_accuracy: 0.3188 - val_loss: 3.5110 - learning_rate: 6.0000e-05\n",
            "Epoch 12/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 964ms/step - accuracy: 0.6602 - loss: 3.3600 - val_accuracy: 0.3382 - val_loss: 3.1742 - learning_rate: 6.0000e-05\n",
            "Epoch 13/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 965ms/step - accuracy: 0.7335 - loss: 3.0208 - val_accuracy: 0.3865 - val_loss: 2.8925 - learning_rate: 6.0000e-05\n",
            "Epoch 14/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 948ms/step - accuracy: 0.7075 - loss: 2.7187 - val_accuracy: 0.4155 - val_loss: 2.6038 - learning_rate: 6.0000e-05\n",
            "Epoch 15/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 956ms/step - accuracy: 0.7082 - loss: 2.4448 - val_accuracy: 0.4155 - val_loss: 2.3527 - learning_rate: 6.0000e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 952ms/step - accuracy: 0.7886 - loss: 2.1815 - val_accuracy: 0.4203 - val_loss: 2.1224 - learning_rate: 6.0000e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 982ms/step - accuracy: 0.7836 - loss: 1.9548 - val_accuracy: 0.4541 - val_loss: 1.9023 - learning_rate: 6.0000e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.7557 - loss: 1.7449 - val_accuracy: 0.5217 - val_loss: 1.6766 - learning_rate: 6.0000e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 956ms/step - accuracy: 0.8082 - loss: 1.5537 - val_accuracy: 0.4783 - val_loss: 1.5409 - learning_rate: 6.0000e-05\n",
            "Epoch 20/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 957ms/step - accuracy: 0.8221 - loss: 1.3851 - val_accuracy: 0.4251 - val_loss: 1.4234 - learning_rate: 6.0000e-05\n",
            "Epoch 21/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 960ms/step - accuracy: 0.7749 - loss: 1.2401 - val_accuracy: 0.5217 - val_loss: 1.2297 - learning_rate: 6.0000e-05\n",
            "Epoch 22/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 964ms/step - accuracy: 0.8008 - loss: 1.0978 - val_accuracy: 0.6087 - val_loss: 1.0545 - learning_rate: 6.0000e-05\n",
            "Epoch 23/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 978ms/step - accuracy: 0.8403 - loss: 0.9702 - val_accuracy: 0.6908 - val_loss: 0.9249 - learning_rate: 6.0000e-05\n",
            "Epoch 24/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.8232 - loss: 0.8598 - val_accuracy: 0.7246 - val_loss: 0.8186 - learning_rate: 6.0000e-05\n",
            "Epoch 25/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 956ms/step - accuracy: 0.8730 - loss: 0.7563 - val_accuracy: 0.7585 - val_loss: 0.7138 - learning_rate: 6.0000e-05\n",
            "Epoch 26/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 962ms/step - accuracy: 0.8908 - loss: 0.6674 - val_accuracy: 0.7343 - val_loss: 0.6341 - learning_rate: 6.0000e-05\n",
            "Epoch 27/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 963ms/step - accuracy: 0.8377 - loss: 0.5938 - val_accuracy: 0.7681 - val_loss: 0.5559 - learning_rate: 6.0000e-05\n",
            "Epoch 28/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 965ms/step - accuracy: 0.8829 - loss: 0.5181 - val_accuracy: 0.7923 - val_loss: 0.4895 - learning_rate: 6.0000e-05\n",
            "Epoch 29/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.8709 - loss: 0.4582 - val_accuracy: 0.7971 - val_loss: 0.4297 - learning_rate: 6.0000e-05\n",
            "Epoch 30/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 960ms/step - accuracy: 0.9404 - loss: 0.3952 - val_accuracy: 0.7923 - val_loss: 0.3805 - learning_rate: 6.0000e-05\n",
            "Epoch 31/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 986ms/step - accuracy: 0.8992 - loss: 0.3470 - val_accuracy: 0.7681 - val_loss: 0.3355 - learning_rate: 6.0000e-05\n",
            "Epoch 32/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 964ms/step - accuracy: 0.8716 - loss: 0.3054 - val_accuracy: 0.7826 - val_loss: 0.2945 - learning_rate: 6.0000e-05\n",
            "Epoch 33/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 946ms/step - accuracy: 0.8988 - loss: 0.2680 - val_accuracy: 0.7440 - val_loss: 0.2702 - learning_rate: 6.0000e-05\n",
            "Epoch 34/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 961ms/step - accuracy: 0.9250 - loss: 0.2308 - val_accuracy: 0.7923 - val_loss: 0.2305 - learning_rate: 6.0000e-05\n",
            "Epoch 35/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 952ms/step - accuracy: 0.9075 - loss: 0.2034 - val_accuracy: 0.7874 - val_loss: 0.2018 - learning_rate: 6.0000e-05\n",
            "Epoch 36/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 956ms/step - accuracy: 0.9094 - loss: 0.1772 - val_accuracy: 0.7778 - val_loss: 0.1845 - learning_rate: 6.0000e-05\n",
            "Epoch 37/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 964ms/step - accuracy: 0.8519 - loss: 0.1583 - val_accuracy: 0.7874 - val_loss: 0.1614 - learning_rate: 6.0000e-05\n",
            "Epoch 38/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 972ms/step - accuracy: 0.8935 - loss: 0.1351 - val_accuracy: 0.7488 - val_loss: 0.1501 - learning_rate: 6.0000e-05\n",
            "Epoch 39/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 941ms/step - accuracy: 0.8752 - loss: 0.1253 - val_accuracy: 0.8068 - val_loss: 0.1244 - learning_rate: 6.0000e-05\n",
            "Epoch 40/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.9047 - loss: 0.1030 - val_accuracy: 0.8116 - val_loss: 0.1097 - learning_rate: 6.0000e-05\n",
            "Epoch 41/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 968ms/step - accuracy: 0.9353 - loss: 0.0878 - val_accuracy: 0.7729 - val_loss: 0.1012 - learning_rate: 6.0000e-05\n",
            "Epoch 42/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 957ms/step - accuracy: 0.8901 - loss: 0.0832 - val_accuracy: 0.7971 - val_loss: 0.0904 - learning_rate: 6.0000e-05\n",
            "Epoch 43/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.9150 - loss: 0.0697 - val_accuracy: 0.7971 - val_loss: 0.0838 - learning_rate: 6.0000e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 963ms/step - accuracy: 0.9407 - loss: 0.0584 - val_accuracy: 0.7729 - val_loss: 0.0822 - learning_rate: 6.0000e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 953ms/step - accuracy: 0.9443 - loss: 0.0504 - val_accuracy: 0.8116 - val_loss: 0.0712 - learning_rate: 6.0000e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 947ms/step - accuracy: 0.9449 - loss: 0.0443 - val_accuracy: 0.7729 - val_loss: 0.0745 - learning_rate: 6.0000e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 961ms/step - accuracy: 0.9452 - loss: 0.0398 - val_accuracy: 0.7874 - val_loss: 0.0628 - learning_rate: 6.0000e-05\n",
            "Epoch 48/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 961ms/step - accuracy: 0.9030 - loss: 0.0387 - val_accuracy: 0.8068 - val_loss: 0.0530 - learning_rate: 6.0000e-05\n",
            "Epoch 49/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 957ms/step - accuracy: 0.9337 - loss: 0.0307 - val_accuracy: 0.7971 - val_loss: 0.0511 - learning_rate: 6.0000e-05\n",
            "Epoch 50/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 959ms/step - accuracy: 0.9084 - loss: 0.0296 - val_accuracy: 0.7971 - val_loss: 0.0463 - learning_rate: 6.0000e-05\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 228ms/step - accuracy: 0.7564 - loss: 0.0520\n",
            "Final Test Accuracy: 0.7971\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 3s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          AD       0.83      0.78      0.81        69\n",
            "        EMCI       0.84      0.74      0.78        69\n",
            "        LMCI       0.74      0.87      0.80        69\n",
            "\n",
            "    accuracy                           0.80       207\n",
            "   macro avg       0.80      0.80      0.80       207\n",
            "weighted avg       0.80      0.80      0.80       207\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[54  7  8]\n",
            " [ 5 51 13]\n",
            " [ 6  3 60]]\n",
            "Accuracy for AD: 78.26%\n",
            "Accuracy for EMCI: 73.91%\n",
            "Accuracy for LMCI: 86.96%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "batch size = 16 , epcohs = 75"
      ],
      "metadata": {
        "id": "rsvirJFLcAQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Set seed for reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Image dimensions and batch size\n",
        "IMG_HEIGHT = 299\n",
        "IMG_WIDTH = 299\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 75\n",
        "PATIENCE = 15\n",
        "\n",
        "# Image data generators with augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    brightness_range=[0.6, 1.4]\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Data generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Compute class weights to handle class imbalance\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_generator.classes),\n",
        "    y=train_generator.classes\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# Load EfficientNetB7 model\n",
        "base_model = tf.keras.applications.EfficientNetB7(\n",
        "    weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
        ")\n",
        "\n",
        "# Unfreeze all layers in the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Custom layers on top of EfficientNetB7\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(3, activation='softmax')  # Adjust the number of classes accordingly\n",
        "])\n",
        "\n",
        "# Focal loss implementation\n",
        "def focal_loss(gamma=2., alpha=0.25):\n",
        "    cce = tf.keras.losses.CategoricalCrossentropy()\n",
        "    def loss(y_true, y_pred):\n",
        "        cce_loss = cce(y_true, y_pred)\n",
        "        p_t = tf.reduce_sum(y_true * y_pred, axis=-1)\n",
        "        modulating_factor = tf.pow(1.0 - p_t, gamma)\n",
        "        alpha_weight_factor = tf.reduce_sum(alpha * y_true, axis=-1)\n",
        "        return modulating_factor * alpha_weight_factor * cce_loss\n",
        "    return loss\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=1e-5),  # Adjusted learning rate for fine-tuning\n",
        "    loss=focal_loss(gamma=2., alpha=0.25),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Learning rate scheduler with warm-up\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 5:\n",
        "        return lr + 1e-5\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "# Callbacks\n",
        "lr_reduction = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss', patience=4, factor=0.3, min_lr=1e-6\n",
        ")\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=PATIENCE, restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=test_generator,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[lr_reduction, early_stopping, lr_scheduler],\n",
        "    class_weight=class_weights,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f\"Final Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Predictions and class-wise metrics\n",
        "y_pred = model.predict(test_generator)\n",
        "y_pred_classes = np.argmax(y_pred, axis=-1)\n",
        "y_true = test_generator.classes\n",
        "\n",
        "# Classification Report\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred_classes, target_names=class_labels))\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
        "print(conf_matrix)\n",
        "\n",
        "# Class-wise Accuracy\n",
        "class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
        "for label, acc in zip(class_labels, class_accuracies):\n",
        "    print(f\"Accuracy for {label}: {acc * 100:.2f}%\")\n",
        "\n",
        "# Save the model\n",
        "model.save(\"efficientnetb7_ad_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1p8IYhNvbucQ",
        "outputId": "af41d1b7-353d-41a8-f6cb-3bc79444d414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 483 images belonging to 3 classes.\n",
            "Found 207 images belonging to 3 classes.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ efficientnetb7 (\u001b[38;5;33mFunctional\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m2560\u001b[0m)        │      \u001b[38;5;34m64,097,687\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2560\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │       \u001b[38;5;34m1,311,232\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │           \u001b[38;5;34m1,539\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ efficientnetb7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2560</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">64,097,687</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2560</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,311,232</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,539</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m65,410,458\u001b[0m (249.52 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,410,458</span> (249.52 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m65,099,731\u001b[0m (248.34 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,099,731</span> (248.34 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m310,727\u001b[0m (1.19 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">310,727</span> (1.19 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m492s\u001b[0m 7s/step - accuracy: 0.3103 - loss: 8.5819 - val_accuracy: 0.3333 - val_loss: 8.3792 - learning_rate: 2.0000e-05\n",
            "Epoch 2/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 982ms/step - accuracy: 0.3161 - loss: 8.2853 - val_accuracy: 0.3140 - val_loss: 7.9988 - learning_rate: 3.0000e-05\n",
            "Epoch 3/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 949ms/step - accuracy: 0.4398 - loss: 7.8658 - val_accuracy: 0.3140 - val_loss: 7.5174 - learning_rate: 4.0000e-05\n",
            "Epoch 4/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.3935 - loss: 7.3664 - val_accuracy: 0.3768 - val_loss: 6.9508 - learning_rate: 5.0000e-05\n",
            "Epoch 5/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 999ms/step - accuracy: 0.4187 - loss: 6.7800 - val_accuracy: 0.3140 - val_loss: 6.3233 - learning_rate: 6.0000e-05\n",
            "Epoch 6/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 971ms/step - accuracy: 0.4637 - loss: 6.1618 - val_accuracy: 0.3527 - val_loss: 5.7492 - learning_rate: 6.0000e-05\n",
            "Epoch 7/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 957ms/step - accuracy: 0.5257 - loss: 5.5930 - val_accuracy: 0.3043 - val_loss: 5.2269 - learning_rate: 6.0000e-05\n",
            "Epoch 8/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 966ms/step - accuracy: 0.5387 - loss: 5.0754 - val_accuracy: 0.3237 - val_loss: 4.7493 - learning_rate: 6.0000e-05\n",
            "Epoch 9/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 958ms/step - accuracy: 0.5635 - loss: 4.5975 - val_accuracy: 0.3478 - val_loss: 4.3117 - learning_rate: 6.0000e-05\n",
            "Epoch 10/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 958ms/step - accuracy: 0.6053 - loss: 4.1677 - val_accuracy: 0.3527 - val_loss: 3.9117 - learning_rate: 6.0000e-05\n",
            "Epoch 11/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.6093 - loss: 3.7649 - val_accuracy: 0.3623 - val_loss: 3.5446 - learning_rate: 6.0000e-05\n",
            "Epoch 12/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 955ms/step - accuracy: 0.6876 - loss: 3.3980 - val_accuracy: 0.3961 - val_loss: 3.2090 - learning_rate: 6.0000e-05\n",
            "Epoch 13/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 948ms/step - accuracy: 0.6993 - loss: 3.0685 - val_accuracy: 0.3478 - val_loss: 2.9007 - learning_rate: 6.0000e-05\n",
            "Epoch 14/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 961ms/step - accuracy: 0.6804 - loss: 2.7594 - val_accuracy: 0.3671 - val_loss: 2.6211 - learning_rate: 6.0000e-05\n",
            "Epoch 15/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 958ms/step - accuracy: 0.7359 - loss: 2.4822 - val_accuracy: 0.3623 - val_loss: 2.3640 - learning_rate: 6.0000e-05\n",
            "Epoch 16/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.7434 - loss: 2.2275 - val_accuracy: 0.3865 - val_loss: 2.1304 - learning_rate: 6.0000e-05\n",
            "Epoch 17/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 949ms/step - accuracy: 0.7409 - loss: 2.0044 - val_accuracy: 0.4783 - val_loss: 1.9092 - learning_rate: 6.0000e-05\n",
            "Epoch 18/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.7728 - loss: 1.7844 - val_accuracy: 0.5072 - val_loss: 1.7123 - learning_rate: 6.0000e-05\n",
            "Epoch 19/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 949ms/step - accuracy: 0.8115 - loss: 1.5918 - val_accuracy: 0.5652 - val_loss: 1.5255 - learning_rate: 6.0000e-05\n",
            "Epoch 20/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.8107 - loss: 1.4207 - val_accuracy: 0.5990 - val_loss: 1.3613 - learning_rate: 6.0000e-05\n",
            "Epoch 21/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 995ms/step - accuracy: 0.8311 - loss: 1.2628 - val_accuracy: 0.6280 - val_loss: 1.2058 - learning_rate: 6.0000e-05\n",
            "Epoch 22/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 959ms/step - accuracy: 0.8746 - loss: 1.1235 - val_accuracy: 0.6957 - val_loss: 1.0675 - learning_rate: 6.0000e-05\n",
            "Epoch 23/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 953ms/step - accuracy: 0.8519 - loss: 0.9992 - val_accuracy: 0.7005 - val_loss: 0.9523 - learning_rate: 6.0000e-05\n",
            "Epoch 24/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 952ms/step - accuracy: 0.8198 - loss: 0.8887 - val_accuracy: 0.7391 - val_loss: 0.8358 - learning_rate: 6.0000e-05\n",
            "Epoch 25/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 959ms/step - accuracy: 0.8351 - loss: 0.7858 - val_accuracy: 0.7536 - val_loss: 0.7428 - learning_rate: 6.0000e-05\n",
            "Epoch 26/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 977ms/step - accuracy: 0.8591 - loss: 0.6927 - val_accuracy: 0.7246 - val_loss: 0.6539 - learning_rate: 6.0000e-05\n",
            "Epoch 27/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 953ms/step - accuracy: 0.8685 - loss: 0.6110 - val_accuracy: 0.7826 - val_loss: 0.5744 - learning_rate: 6.0000e-05\n",
            "Epoch 28/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 952ms/step - accuracy: 0.9002 - loss: 0.5365 - val_accuracy: 0.7874 - val_loss: 0.5060 - learning_rate: 6.0000e-05\n",
            "Epoch 29/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 959ms/step - accuracy: 0.8774 - loss: 0.4745 - val_accuracy: 0.7729 - val_loss: 0.4476 - learning_rate: 6.0000e-05\n",
            "Epoch 30/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 956ms/step - accuracy: 0.8928 - loss: 0.4131 - val_accuracy: 0.8019 - val_loss: 0.3924 - learning_rate: 6.0000e-05\n",
            "Epoch 31/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 966ms/step - accuracy: 0.9188 - loss: 0.3619 - val_accuracy: 0.7923 - val_loss: 0.3488 - learning_rate: 6.0000e-05\n",
            "Epoch 32/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 974ms/step - accuracy: 0.9082 - loss: 0.3182 - val_accuracy: 0.7874 - val_loss: 0.3112 - learning_rate: 6.0000e-05\n",
            "Epoch 33/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.8882 - loss: 0.2792 - val_accuracy: 0.7826 - val_loss: 0.2696 - learning_rate: 6.0000e-05\n",
            "Epoch 34/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 978ms/step - accuracy: 0.9067 - loss: 0.2427 - val_accuracy: 0.7585 - val_loss: 0.2395 - learning_rate: 6.0000e-05\n",
            "Epoch 35/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.9123 - loss: 0.2103 - val_accuracy: 0.7923 - val_loss: 0.2120 - learning_rate: 6.0000e-05\n",
            "Epoch 36/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 973ms/step - accuracy: 0.8957 - loss: 0.1874 - val_accuracy: 0.7778 - val_loss: 0.1914 - learning_rate: 6.0000e-05\n",
            "Epoch 37/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 956ms/step - accuracy: 0.8788 - loss: 0.1637 - val_accuracy: 0.7826 - val_loss: 0.1662 - learning_rate: 6.0000e-05\n",
            "Epoch 38/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 960ms/step - accuracy: 0.9299 - loss: 0.1394 - val_accuracy: 0.7923 - val_loss: 0.1489 - learning_rate: 6.0000e-05\n",
            "Epoch 39/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 954ms/step - accuracy: 0.9192 - loss: 0.1229 - val_accuracy: 0.8116 - val_loss: 0.1297 - learning_rate: 6.0000e-05\n",
            "Epoch 40/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 959ms/step - accuracy: 0.9297 - loss: 0.1052 - val_accuracy: 0.8019 - val_loss: 0.1164 - learning_rate: 6.0000e-05\n",
            "Epoch 41/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 986ms/step - accuracy: 0.8709 - loss: 0.0984 - val_accuracy: 0.7826 - val_loss: 0.1048 - learning_rate: 6.0000e-05\n",
            "Epoch 42/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 962ms/step - accuracy: 0.9335 - loss: 0.0785 - val_accuracy: 0.7971 - val_loss: 0.0953 - learning_rate: 6.0000e-05\n",
            "Epoch 43/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.9296 - loss: 0.0706 - val_accuracy: 0.8019 - val_loss: 0.0834 - learning_rate: 6.0000e-05\n",
            "Epoch 44/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 960ms/step - accuracy: 0.9275 - loss: 0.0600 - val_accuracy: 0.7971 - val_loss: 0.0759 - learning_rate: 6.0000e-05\n",
            "Epoch 45/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 959ms/step - accuracy: 0.9478 - loss: 0.0506 - val_accuracy: 0.8164 - val_loss: 0.0684 - learning_rate: 6.0000e-05\n",
            "Epoch 46/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 979ms/step - accuracy: 0.9212 - loss: 0.0462 - val_accuracy: 0.7874 - val_loss: 0.0650 - learning_rate: 6.0000e-05\n",
            "Epoch 47/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.9750 - loss: 0.0371 - val_accuracy: 0.8164 - val_loss: 0.0573 - learning_rate: 6.0000e-05\n",
            "Epoch 48/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 969ms/step - accuracy: 0.9277 - loss: 0.0350 - val_accuracy: 0.8164 - val_loss: 0.0550 - learning_rate: 6.0000e-05\n",
            "Epoch 49/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.9294 - loss: 0.0307 - val_accuracy: 0.8116 - val_loss: 0.0472 - learning_rate: 6.0000e-05\n",
            "Epoch 50/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 942ms/step - accuracy: 0.8949 - loss: 0.0294 - val_accuracy: 0.8164 - val_loss: 0.0460 - learning_rate: 6.0000e-05\n",
            "Epoch 51/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 951ms/step - accuracy: 0.9574 - loss: 0.0234 - val_accuracy: 0.7778 - val_loss: 0.0515 - learning_rate: 6.0000e-05\n",
            "Epoch 52/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 962ms/step - accuracy: 0.8880 - loss: 0.0293 - val_accuracy: 0.7923 - val_loss: 0.0437 - learning_rate: 6.0000e-05\n",
            "Epoch 53/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 966ms/step - accuracy: 0.8932 - loss: 0.0262 - val_accuracy: 0.8309 - val_loss: 0.0397 - learning_rate: 6.0000e-05\n",
            "Epoch 54/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 969ms/step - accuracy: 0.9458 - loss: 0.0197 - val_accuracy: 0.8116 - val_loss: 0.0368 - learning_rate: 6.0000e-05\n",
            "Epoch 55/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 967ms/step - accuracy: 0.9514 - loss: 0.0172 - val_accuracy: 0.8164 - val_loss: 0.0355 - learning_rate: 6.0000e-05\n",
            "Epoch 56/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 949ms/step - accuracy: 0.9299 - loss: 0.0158 - val_accuracy: 0.8116 - val_loss: 0.0335 - learning_rate: 6.0000e-05\n",
            "Epoch 57/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 949ms/step - accuracy: 0.9193 - loss: 0.0139 - val_accuracy: 0.8261 - val_loss: 0.0354 - learning_rate: 6.0000e-05\n",
            "Epoch 58/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 938ms/step - accuracy: 0.9499 - loss: 0.0117 - val_accuracy: 0.8116 - val_loss: 0.0326 - learning_rate: 6.0000e-05\n",
            "Epoch 59/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 964ms/step - accuracy: 0.9227 - loss: 0.0133 - val_accuracy: 0.8019 - val_loss: 0.0317 - learning_rate: 6.0000e-05\n",
            "Epoch 60/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.9324 - loss: 0.0157 - val_accuracy: 0.7971 - val_loss: 0.0356 - learning_rate: 6.0000e-05\n",
            "Epoch 61/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 959ms/step - accuracy: 0.9476 - loss: 0.0094 - val_accuracy: 0.8068 - val_loss: 0.0303 - learning_rate: 6.0000e-05\n",
            "Epoch 62/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 959ms/step - accuracy: 0.9293 - loss: 0.0107 - val_accuracy: 0.6763 - val_loss: 0.0720 - learning_rate: 6.0000e-05\n",
            "Epoch 63/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 960ms/step - accuracy: 0.8500 - loss: 0.0226 - val_accuracy: 0.7729 - val_loss: 0.0433 - learning_rate: 6.0000e-05\n",
            "Epoch 64/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 944ms/step - accuracy: 0.8673 - loss: 0.0198 - val_accuracy: 0.7923 - val_loss: 0.0378 - learning_rate: 6.0000e-05\n",
            "Epoch 65/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 938ms/step - accuracy: 0.9452 - loss: 0.0111 - val_accuracy: 0.7826 - val_loss: 0.0331 - learning_rate: 1.8000e-05\n",
            "Epoch 66/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 945ms/step - accuracy: 0.9412 - loss: 0.0113 - val_accuracy: 0.7778 - val_loss: 0.0425 - learning_rate: 1.8000e-05\n",
            "Epoch 67/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 934ms/step - accuracy: 0.9206 - loss: 0.0120 - val_accuracy: 0.7874 - val_loss: 0.0312 - learning_rate: 1.8000e-05\n",
            "Epoch 68/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 931ms/step - accuracy: 0.9611 - loss: 0.0084 - val_accuracy: 0.7923 - val_loss: 0.0316 - learning_rate: 1.8000e-05\n",
            "Epoch 69/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.9459 - loss: 0.0097 - val_accuracy: 0.7923 - val_loss: 0.0310 - learning_rate: 5.4000e-06\n",
            "Epoch 70/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 942ms/step - accuracy: 0.9550 - loss: 0.0084 - val_accuracy: 0.7971 - val_loss: 0.0309 - learning_rate: 5.4000e-06\n",
            "Epoch 71/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 953ms/step - accuracy: 0.9444 - loss: 0.0092 - val_accuracy: 0.7971 - val_loss: 0.0306 - learning_rate: 5.4000e-06\n",
            "Epoch 72/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 948ms/step - accuracy: 0.9431 - loss: 0.0107 - val_accuracy: 0.8019 - val_loss: 0.0307 - learning_rate: 5.4000e-06\n",
            "Epoch 73/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 933ms/step - accuracy: 0.9720 - loss: 0.0073 - val_accuracy: 0.7923 - val_loss: 0.0308 - learning_rate: 1.6200e-06\n",
            "Epoch 74/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 948ms/step - accuracy: 0.9394 - loss: 0.0090 - val_accuracy: 0.7971 - val_loss: 0.0306 - learning_rate: 1.6200e-06\n",
            "Epoch 75/75\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 948ms/step - accuracy: 0.9203 - loss: 0.0108 - val_accuracy: 0.7971 - val_loss: 0.0304 - learning_rate: 1.6200e-06\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 226ms/step - accuracy: 0.7758 - loss: 0.0412\n",
            "Final Test Accuracy: 0.8068\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          AD       0.84      0.78      0.81        69\n",
            "        EMCI       0.81      0.81      0.81        69\n",
            "        LMCI       0.77      0.83      0.80        69\n",
            "\n",
            "    accuracy                           0.81       207\n",
            "   macro avg       0.81      0.81      0.81       207\n",
            "weighted avg       0.81      0.81      0.81       207\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[54  4 11]\n",
            " [ 7 56  6]\n",
            " [ 3  9 57]]\n",
            "Accuracy for AD: 78.26%\n",
            "Accuracy for EMCI: 81.16%\n",
            "Accuracy for LMCI: 82.61%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "batch size = 16 , epcohs = 100"
      ],
      "metadata": {
        "id": "KvQZDchxcGet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Set seed for reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Image dimensions and batch size\n",
        "IMG_HEIGHT = 299\n",
        "IMG_WIDTH = 299\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 100\n",
        "PATIENCE = 15\n",
        "\n",
        "# Image data generators with augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    brightness_range=[0.6, 1.4]\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Data generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Compute class weights to handle class imbalance\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_generator.classes),\n",
        "    y=train_generator.classes\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# Load EfficientNetB7 model\n",
        "base_model = tf.keras.applications.EfficientNetB7(\n",
        "    weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
        ")\n",
        "\n",
        "# Unfreeze all layers in the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Custom layers on top of EfficientNetB7\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(3, activation='softmax')  # Adjust the number of classes accordingly\n",
        "])\n",
        "\n",
        "# Focal loss implementation\n",
        "def focal_loss(gamma=2., alpha=0.25):\n",
        "    cce = tf.keras.losses.CategoricalCrossentropy()\n",
        "    def loss(y_true, y_pred):\n",
        "        cce_loss = cce(y_true, y_pred)\n",
        "        p_t = tf.reduce_sum(y_true * y_pred, axis=-1)\n",
        "        modulating_factor = tf.pow(1.0 - p_t, gamma)\n",
        "        alpha_weight_factor = tf.reduce_sum(alpha * y_true, axis=-1)\n",
        "        return modulating_factor * alpha_weight_factor * cce_loss\n",
        "    return loss\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=1e-5),  # Adjusted learning rate for fine-tuning\n",
        "    loss=focal_loss(gamma=2., alpha=0.25),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Learning rate scheduler with warm-up\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 5:\n",
        "        return lr + 1e-5\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "# Callbacks\n",
        "lr_reduction = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss', patience=4, factor=0.3, min_lr=1e-6\n",
        ")\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=PATIENCE, restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=test_generator,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[lr_reduction, early_stopping, lr_scheduler],\n",
        "    class_weight=class_weights,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f\"Final Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Predictions and class-wise metrics\n",
        "y_pred = model.predict(test_generator)\n",
        "y_pred_classes = np.argmax(y_pred, axis=-1)\n",
        "y_true = test_generator.classes\n",
        "\n",
        "# Classification Report\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred_classes, target_names=class_labels))\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
        "print(conf_matrix)\n",
        "\n",
        "# Class-wise Accuracy\n",
        "class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
        "for label, acc in zip(class_labels, class_accuracies):\n",
        "    print(f\"Accuracy for {label}: {acc * 100:.2f}%\")\n",
        "\n",
        "# Save the model\n",
        "model.save(\"efficientnetb7_ad_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aS4PLIXubxvc",
        "outputId": "f36da821-2fa1-4faa-d5c4-775bfa97e838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 483 images belonging to 3 classes.\n",
            "Found 207 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5\n",
            "\u001b[1m258076736/258076736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ efficientnetb7 (\u001b[38;5;33mFunctional\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m2560\u001b[0m)        │      \u001b[38;5;34m64,097,687\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2560\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │       \u001b[38;5;34m1,311,232\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │           \u001b[38;5;34m1,539\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ efficientnetb7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2560</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">64,097,687</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2560</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,311,232</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,539</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m65,410,458\u001b[0m (249.52 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,410,458</span> (249.52 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m65,099,731\u001b[0m (248.34 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,099,731</span> (248.34 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m310,727\u001b[0m (1.19 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">310,727</span> (1.19 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m629s\u001b[0m 11s/step - accuracy: 0.3658 - loss: 8.5956 - val_accuracy: 0.3333 - val_loss: 8.3943 - learning_rate: 2.0000e-05\n",
            "Epoch 2/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 976ms/step - accuracy: 0.3752 - loss: 8.2979 - val_accuracy: 0.3043 - val_loss: 8.0198 - learning_rate: 3.0000e-05\n",
            "Epoch 3/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 958ms/step - accuracy: 0.3512 - loss: 7.8932 - val_accuracy: 0.3333 - val_loss: 7.5361 - learning_rate: 4.0000e-05\n",
            "Epoch 4/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 994ms/step - accuracy: 0.4044 - loss: 7.3847 - val_accuracy: 0.3623 - val_loss: 6.9692 - learning_rate: 5.0000e-05\n",
            "Epoch 5/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 1s/step - accuracy: 0.4173 - loss: 6.8016 - val_accuracy: 0.3092 - val_loss: 6.3443 - learning_rate: 6.0000e-05\n",
            "Epoch 6/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 968ms/step - accuracy: 0.4548 - loss: 6.1841 - val_accuracy: 0.3237 - val_loss: 5.7716 - learning_rate: 6.0000e-05\n",
            "Epoch 7/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.5510 - loss: 5.6089 - val_accuracy: 0.3913 - val_loss: 5.2482 - learning_rate: 6.0000e-05\n",
            "Epoch 8/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.5112 - loss: 5.0945 - val_accuracy: 0.3865 - val_loss: 4.7676 - learning_rate: 6.0000e-05\n",
            "Epoch 9/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 960ms/step - accuracy: 0.5552 - loss: 4.6242 - val_accuracy: 0.3768 - val_loss: 4.3292 - learning_rate: 6.0000e-05\n",
            "Epoch 10/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - accuracy: 0.5843 - loss: 4.1813 - val_accuracy: 0.3720 - val_loss: 3.9283 - learning_rate: 6.0000e-05\n",
            "Epoch 11/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 959ms/step - accuracy: 0.6395 - loss: 3.7793 - val_accuracy: 0.3527 - val_loss: 3.5622 - learning_rate: 6.0000e-05\n",
            "Epoch 12/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 954ms/step - accuracy: 0.6406 - loss: 3.4111 - val_accuracy: 0.3671 - val_loss: 3.2237 - learning_rate: 6.0000e-05\n",
            "Epoch 13/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 982ms/step - accuracy: 0.6632 - loss: 3.0844 - val_accuracy: 0.3671 - val_loss: 2.9195 - learning_rate: 6.0000e-05\n",
            "Epoch 14/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 977ms/step - accuracy: 0.6867 - loss: 2.7742 - val_accuracy: 0.3961 - val_loss: 2.6427 - learning_rate: 6.0000e-05\n",
            "Epoch 15/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 959ms/step - accuracy: 0.7230 - loss: 2.4855 - val_accuracy: 0.3768 - val_loss: 2.3794 - learning_rate: 6.0000e-05\n",
            "Epoch 16/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 964ms/step - accuracy: 0.7510 - loss: 2.2338 - val_accuracy: 0.4348 - val_loss: 2.1389 - learning_rate: 6.0000e-05\n",
            "Epoch 17/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.7939 - loss: 1.9957 - val_accuracy: 0.4928 - val_loss: 1.9182 - learning_rate: 6.0000e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 977ms/step - accuracy: 0.8013 - loss: 1.7861 - val_accuracy: 0.5217 - val_loss: 1.7207 - learning_rate: 6.0000e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.8605 - loss: 1.5879 - val_accuracy: 0.5507 - val_loss: 1.5344 - learning_rate: 6.0000e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 969ms/step - accuracy: 0.8200 - loss: 1.4238 - val_accuracy: 0.5314 - val_loss: 1.3893 - learning_rate: 6.0000e-05\n",
            "Epoch 21/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 966ms/step - accuracy: 0.7939 - loss: 1.2698 - val_accuracy: 0.6232 - val_loss: 1.2174 - learning_rate: 6.0000e-05\n",
            "Epoch 22/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.8211 - loss: 1.1250 - val_accuracy: 0.6280 - val_loss: 1.0915 - learning_rate: 6.0000e-05\n",
            "Epoch 23/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 988ms/step - accuracy: 0.8330 - loss: 0.9999 - val_accuracy: 0.6425 - val_loss: 0.9594 - learning_rate: 6.0000e-05\n",
            "Epoch 24/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 959ms/step - accuracy: 0.8160 - loss: 0.8905 - val_accuracy: 0.7150 - val_loss: 0.8410 - learning_rate: 6.0000e-05\n",
            "Epoch 25/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 967ms/step - accuracy: 0.8428 - loss: 0.7832 - val_accuracy: 0.7343 - val_loss: 0.7437 - learning_rate: 6.0000e-05\n",
            "Epoch 26/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 965ms/step - accuracy: 0.8515 - loss: 0.6927 - val_accuracy: 0.7343 - val_loss: 0.6581 - learning_rate: 6.0000e-05\n",
            "Epoch 27/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.9018 - loss: 0.6072 - val_accuracy: 0.7295 - val_loss: 0.5804 - learning_rate: 6.0000e-05\n",
            "Epoch 28/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 954ms/step - accuracy: 0.9178 - loss: 0.5333 - val_accuracy: 0.7585 - val_loss: 0.5133 - learning_rate: 6.0000e-05\n",
            "Epoch 29/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 959ms/step - accuracy: 0.8732 - loss: 0.4767 - val_accuracy: 0.6957 - val_loss: 0.4728 - learning_rate: 6.0000e-05\n",
            "Epoch 30/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 964ms/step - accuracy: 0.8628 - loss: 0.4169 - val_accuracy: 0.7585 - val_loss: 0.3990 - learning_rate: 6.0000e-05\n",
            "Epoch 31/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 957ms/step - accuracy: 0.8978 - loss: 0.3641 - val_accuracy: 0.7874 - val_loss: 0.3504 - learning_rate: 6.0000e-05\n",
            "Epoch 32/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.9072 - loss: 0.3183 - val_accuracy: 0.7633 - val_loss: 0.3138 - learning_rate: 6.0000e-05\n",
            "Epoch 33/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 963ms/step - accuracy: 0.8577 - loss: 0.2814 - val_accuracy: 0.7585 - val_loss: 0.2750 - learning_rate: 6.0000e-05\n",
            "Epoch 34/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 972ms/step - accuracy: 0.9300 - loss: 0.2412 - val_accuracy: 0.7923 - val_loss: 0.2445 - learning_rate: 6.0000e-05\n",
            "Epoch 35/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 975ms/step - accuracy: 0.8923 - loss: 0.2136 - val_accuracy: 0.8116 - val_loss: 0.2106 - learning_rate: 6.0000e-05\n",
            "Epoch 36/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.9037 - loss: 0.1881 - val_accuracy: 0.7874 - val_loss: 0.1855 - learning_rate: 6.0000e-05\n",
            "Epoch 37/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 0.9176 - loss: 0.1609 - val_accuracy: 0.8019 - val_loss: 0.1651 - learning_rate: 6.0000e-05\n",
            "Epoch 38/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 956ms/step - accuracy: 0.8818 - loss: 0.1422 - val_accuracy: 0.8019 - val_loss: 0.1478 - learning_rate: 6.0000e-05\n",
            "Epoch 39/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 956ms/step - accuracy: 0.8667 - loss: 0.1281 - val_accuracy: 0.7874 - val_loss: 0.1300 - learning_rate: 6.0000e-05\n",
            "Epoch 40/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 958ms/step - accuracy: 0.8880 - loss: 0.1077 - val_accuracy: 0.7729 - val_loss: 0.1205 - learning_rate: 6.0000e-05\n",
            "Epoch 41/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 969ms/step - accuracy: 0.9264 - loss: 0.0930 - val_accuracy: 0.7874 - val_loss: 0.1053 - learning_rate: 6.0000e-05\n",
            "Epoch 42/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 974ms/step - accuracy: 0.8941 - loss: 0.0829 - val_accuracy: 0.7971 - val_loss: 0.0929 - learning_rate: 6.0000e-05\n",
            "Epoch 43/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 960ms/step - accuracy: 0.9398 - loss: 0.0705 - val_accuracy: 0.7971 - val_loss: 0.0883 - learning_rate: 6.0000e-05\n",
            "Epoch 44/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 967ms/step - accuracy: 0.9676 - loss: 0.0586 - val_accuracy: 0.8019 - val_loss: 0.0805 - learning_rate: 6.0000e-05\n",
            "Epoch 45/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.9210 - loss: 0.0546 - val_accuracy: 0.8019 - val_loss: 0.0728 - learning_rate: 6.0000e-05\n",
            "Epoch 46/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 956ms/step - accuracy: 0.9376 - loss: 0.0455 - val_accuracy: 0.7923 - val_loss: 0.0655 - learning_rate: 6.0000e-05\n",
            "Epoch 47/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 955ms/step - accuracy: 0.9353 - loss: 0.0401 - val_accuracy: 0.7971 - val_loss: 0.0595 - learning_rate: 6.0000e-05\n",
            "Epoch 48/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 973ms/step - accuracy: 0.9222 - loss: 0.0382 - val_accuracy: 0.7923 - val_loss: 0.0563 - learning_rate: 6.0000e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 970ms/step - accuracy: 0.9352 - loss: 0.0309 - val_accuracy: 0.7874 - val_loss: 0.0537 - learning_rate: 6.0000e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 955ms/step - accuracy: 0.9009 - loss: 0.0329 - val_accuracy: 0.7681 - val_loss: 0.0487 - learning_rate: 6.0000e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 967ms/step - accuracy: 0.9089 - loss: 0.0273 - val_accuracy: 0.7923 - val_loss: 0.0467 - learning_rate: 6.0000e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 970ms/step - accuracy: 0.9084 - loss: 0.0255 - val_accuracy: 0.7923 - val_loss: 0.0423 - learning_rate: 6.0000e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 968ms/step - accuracy: 0.9365 - loss: 0.0236 - val_accuracy: 0.7826 - val_loss: 0.0462 - learning_rate: 6.0000e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 956ms/step - accuracy: 0.9570 - loss: 0.0179 - val_accuracy: 0.8019 - val_loss: 0.0424 - learning_rate: 6.0000e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 954ms/step - accuracy: 0.9697 - loss: 0.0146 - val_accuracy: 0.7971 - val_loss: 0.0405 - learning_rate: 6.0000e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 954ms/step - accuracy: 0.9498 - loss: 0.0146 - val_accuracy: 0.7874 - val_loss: 0.0386 - learning_rate: 6.0000e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 998ms/step - accuracy: 0.9364 - loss: 0.0140 - val_accuracy: 0.8068 - val_loss: 0.0372 - learning_rate: 6.0000e-05\n",
            "Epoch 58/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 939ms/step - accuracy: 0.9286 - loss: 0.0140 - val_accuracy: 0.7874 - val_loss: 0.0417 - learning_rate: 6.0000e-05\n",
            "Epoch 59/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 962ms/step - accuracy: 0.9476 - loss: 0.0127 - val_accuracy: 0.7778 - val_loss: 0.0381 - learning_rate: 6.0000e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 952ms/step - accuracy: 0.9459 - loss: 0.0115 - val_accuracy: 0.7729 - val_loss: 0.0365 - learning_rate: 6.0000e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 966ms/step - accuracy: 0.9580 - loss: 0.0097 - val_accuracy: 0.8019 - val_loss: 0.0331 - learning_rate: 6.0000e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 957ms/step - accuracy: 0.9744 - loss: 0.0080 - val_accuracy: 0.7874 - val_loss: 0.0342 - learning_rate: 6.0000e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 958ms/step - accuracy: 0.9174 - loss: 0.0114 - val_accuracy: 0.8019 - val_loss: 0.0305 - learning_rate: 6.0000e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 968ms/step - accuracy: 0.9399 - loss: 0.0087 - val_accuracy: 0.7826 - val_loss: 0.0333 - learning_rate: 6.0000e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 949ms/step - accuracy: 0.9530 - loss: 0.0080 - val_accuracy: 0.7874 - val_loss: 0.0322 - learning_rate: 6.0000e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 962ms/step - accuracy: 0.9546 - loss: 0.0072 - val_accuracy: 0.7874 - val_loss: 0.0340 - learning_rate: 6.0000e-05\n",
            "Epoch 67/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 955ms/step - accuracy: 0.9409 - loss: 0.0072 - val_accuracy: 0.7729 - val_loss: 0.0404 - learning_rate: 1.8000e-05\n",
            "Epoch 68/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 953ms/step - accuracy: 0.9219 - loss: 0.0095 - val_accuracy: 0.7826 - val_loss: 0.0392 - learning_rate: 1.8000e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 935ms/step - accuracy: 0.9239 - loss: 0.0099 - val_accuracy: 0.7874 - val_loss: 0.0325 - learning_rate: 1.8000e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - accuracy: 0.9401 - loss: 0.0091 - val_accuracy: 0.7971 - val_loss: 0.0303 - learning_rate: 1.8000e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.9312 - loss: 0.0093 - val_accuracy: 0.7971 - val_loss: 0.0292 - learning_rate: 1.8000e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 944ms/step - accuracy: 0.9442 - loss: 0.0094 - val_accuracy: 0.7874 - val_loss: 0.0294 - learning_rate: 1.8000e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.9366 - loss: 0.0073 - val_accuracy: 0.7826 - val_loss: 0.0295 - learning_rate: 1.8000e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 974ms/step - accuracy: 0.9476 - loss: 0.0075 - val_accuracy: 0.7681 - val_loss: 0.0331 - learning_rate: 1.8000e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 955ms/step - accuracy: 0.9218 - loss: 0.0095 - val_accuracy: 0.7729 - val_loss: 0.0322 - learning_rate: 5.4000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 955ms/step - accuracy: 0.9512 - loss: 0.0071 - val_accuracy: 0.7729 - val_loss: 0.0314 - learning_rate: 5.4000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 953ms/step - accuracy: 0.9438 - loss: 0.0077 - val_accuracy: 0.7729 - val_loss: 0.0308 - learning_rate: 5.4000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 940ms/step - accuracy: 0.9284 - loss: 0.0078 - val_accuracy: 0.7826 - val_loss: 0.0302 - learning_rate: 5.4000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 954ms/step - accuracy: 0.9536 - loss: 0.0071 - val_accuracy: 0.7874 - val_loss: 0.0297 - learning_rate: 1.6200e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 947ms/step - accuracy: 0.9610 - loss: 0.0064 - val_accuracy: 0.7874 - val_loss: 0.0295 - learning_rate: 1.6200e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 948ms/step - accuracy: 0.9622 - loss: 0.0067 - val_accuracy: 0.7874 - val_loss: 0.0295 - learning_rate: 1.6200e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 957ms/step - accuracy: 0.9697 - loss: 0.0058 - val_accuracy: 0.7874 - val_loss: 0.0294 - learning_rate: 1.6200e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 953ms/step - accuracy: 0.9469 - loss: 0.0092 - val_accuracy: 0.7826 - val_loss: 0.0294 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 944ms/step - accuracy: 0.9784 - loss: 0.0057 - val_accuracy: 0.7826 - val_loss: 0.0293 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 946ms/step - accuracy: 0.9853 - loss: 0.0054 - val_accuracy: 0.7826 - val_loss: 0.0293 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 965ms/step - accuracy: 0.9424 - loss: 0.0072 - val_accuracy: 0.7874 - val_loss: 0.0292 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 959ms/step - accuracy: 0.9582 - loss: 0.0059 - val_accuracy: 0.7826 - val_loss: 0.0292 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - accuracy: 0.9379 - loss: 0.0082 - val_accuracy: 0.7826 - val_loss: 0.0292 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 945ms/step - accuracy: 0.9694 - loss: 0.0052 - val_accuracy: 0.7874 - val_loss: 0.0292 - learning_rate: 1.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 970ms/step - accuracy: 0.9487 - loss: 0.0064 - val_accuracy: 0.7923 - val_loss: 0.0292 - learning_rate: 1.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 964ms/step - accuracy: 0.9473 - loss: 0.0073 - val_accuracy: 0.7874 - val_loss: 0.0291 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 940ms/step - accuracy: 0.9311 - loss: 0.0080 - val_accuracy: 0.7874 - val_loss: 0.0292 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 961ms/step - accuracy: 0.9651 - loss: 0.0065 - val_accuracy: 0.7874 - val_loss: 0.0292 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 967ms/step - accuracy: 0.9459 - loss: 0.0070 - val_accuracy: 0.7971 - val_loss: 0.0290 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 960ms/step - accuracy: 0.9298 - loss: 0.0076 - val_accuracy: 0.7971 - val_loss: 0.0289 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.9590 - loss: 0.0063 - val_accuracy: 0.7971 - val_loss: 0.0290 - learning_rate: 1.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 951ms/step - accuracy: 0.9707 - loss: 0.0057 - val_accuracy: 0.7971 - val_loss: 0.0291 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 958ms/step - accuracy: 0.9682 - loss: 0.0052 - val_accuracy: 0.7971 - val_loss: 0.0290 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.9668 - loss: 0.0065 - val_accuracy: 0.7923 - val_loss: 0.0288 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 957ms/step - accuracy: 0.9381 - loss: 0.0071 - val_accuracy: 0.7971 - val_loss: 0.0288 - learning_rate: 1.0000e-06\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 233ms/step - accuracy: 0.7939 - loss: 0.0300\n",
            "Final Test Accuracy: 0.7971\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          AD       0.80      0.83      0.81        69\n",
            "        EMCI       0.81      0.78      0.79        69\n",
            "        LMCI       0.78      0.78      0.78        69\n",
            "\n",
            "    accuracy                           0.80       207\n",
            "   macro avg       0.80      0.80      0.80       207\n",
            "weighted avg       0.80      0.80      0.80       207\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[57  5  7]\n",
            " [ 7 54  8]\n",
            " [ 7  8 54]]\n",
            "Accuracy for AD: 82.61%\n",
            "Accuracy for EMCI: 78.26%\n",
            "Accuracy for LMCI: 78.26%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "batch size = 32 , epochs = 25"
      ],
      "metadata": {
        "id": "3axdx0eRyD8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Set seed for reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Image dimensions and batch size\n",
        "IMG_HEIGHT = 299\n",
        "IMG_WIDTH = 299\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 25\n",
        "PATIENCE = 15\n",
        "\n",
        "# Image data generators with augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    brightness_range=[0.6, 1.4]\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Data generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Compute class weights to handle class imbalance\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_generator.classes),\n",
        "    y=train_generator.classes\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# Load EfficientNetB7 model\n",
        "base_model = tf.keras.applications.EfficientNetB7(\n",
        "    weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
        ")\n",
        "\n",
        "# Unfreeze all layers in the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Custom layers on top of EfficientNetB7\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(3, activation='softmax')  # Adjust the number of classes accordingly\n",
        "])\n",
        "\n",
        "# Focal loss implementation\n",
        "def focal_loss(gamma=2., alpha=0.25):\n",
        "    cce = tf.keras.losses.CategoricalCrossentropy()\n",
        "    def loss(y_true, y_pred):\n",
        "        cce_loss = cce(y_true, y_pred)\n",
        "        p_t = tf.reduce_sum(y_true * y_pred, axis=-1)\n",
        "        modulating_factor = tf.pow(1.0 - p_t, gamma)\n",
        "        alpha_weight_factor = tf.reduce_sum(alpha * y_true, axis=-1)\n",
        "        return modulating_factor * alpha_weight_factor * cce_loss\n",
        "    return loss\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=1e-5),  # Adjusted learning rate for fine-tuning\n",
        "    loss=focal_loss(gamma=2., alpha=0.25),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Learning rate scheduler with warm-up\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 5:\n",
        "        return lr + 1e-5\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "# Callbacks\n",
        "lr_reduction = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss', patience=4, factor=0.3, min_lr=1e-6\n",
        ")\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=PATIENCE, restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=test_generator,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[lr_reduction, early_stopping, lr_scheduler],\n",
        "    class_weight=class_weights,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f\"Final Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Predictions and class-wise metrics\n",
        "y_pred = model.predict(test_generator)\n",
        "y_pred_classes = np.argmax(y_pred, axis=-1)\n",
        "y_true = test_generator.classes\n",
        "\n",
        "# Classification Report\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred_classes, target_names=class_labels))\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
        "print(conf_matrix)\n",
        "\n",
        "# Class-wise Accuracy\n",
        "class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
        "for label, acc in zip(class_labels, class_accuracies):\n",
        "    print(f\"Accuracy for {label}: {acc * 100:.2f}%\")\n",
        "\n",
        "# Save the model\n",
        "model.save(\"efficientnetb7_ad_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UE9TvU3orn4s",
        "outputId": "0bf1a010-5376-4a33-d3aa-33c32dde86d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 483 images belonging to 3 classes.\n",
            "Found 207 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5\n",
            "\u001b[1m258076736/258076736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ efficientnetb7 (\u001b[38;5;33mFunctional\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m2560\u001b[0m)        │      \u001b[38;5;34m64,097,687\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2560\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │       \u001b[38;5;34m1,311,232\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │           \u001b[38;5;34m1,539\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ efficientnetb7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2560</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">64,097,687</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2560</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,311,232</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,539</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m65,410,458\u001b[0m (249.52 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,410,458</span> (249.52 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m65,099,731\u001b[0m (248.34 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,099,731</span> (248.34 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m310,727\u001b[0m (1.19 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">310,727</span> (1.19 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m675s\u001b[0m 20s/step - accuracy: 0.3445 - loss: 8.6267 - val_accuracy: 0.3333 - val_loss: 8.5090 - learning_rate: 2.0000e-05\n",
            "Epoch 2/25\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.3178 - loss: 8.4585 - val_accuracy: 0.3333 - val_loss: 8.2889 - learning_rate: 3.0000e-05\n",
            "Epoch 3/25\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.3549 - loss: 8.2207 - val_accuracy: 0.2754 - val_loss: 8.0063 - learning_rate: 4.0000e-05\n",
            "Epoch 4/25\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.3879 - loss: 7.9203 - val_accuracy: 0.2705 - val_loss: 7.6681 - learning_rate: 5.0000e-05\n",
            "Epoch 5/25\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.4317 - loss: 7.5534 - val_accuracy: 0.2802 - val_loss: 7.2783 - learning_rate: 6.0000e-05\n",
            "Epoch 6/25\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2s/step - accuracy: 0.4744 - loss: 7.1689 - val_accuracy: 0.3333 - val_loss: 6.9045 - learning_rate: 6.0000e-05\n",
            "Epoch 7/25\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.4723 - loss: 6.7950 - val_accuracy: 0.3333 - val_loss: 6.5526 - learning_rate: 6.0000e-05\n",
            "Epoch 8/25\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - accuracy: 0.4740 - loss: 6.4405 - val_accuracy: 0.3333 - val_loss: 6.2157 - learning_rate: 6.0000e-05\n",
            "Epoch 9/25\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.4998 - loss: 6.0968 - val_accuracy: 0.3333 - val_loss: 5.8923 - learning_rate: 6.0000e-05\n",
            "Epoch 10/25\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.4774 - loss: 5.7740 - val_accuracy: 0.3333 - val_loss: 5.5831 - learning_rate: 6.0000e-05\n",
            "Epoch 11/25\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.5516 - loss: 5.4473 - val_accuracy: 0.3333 - val_loss: 5.2901 - learning_rate: 6.0000e-05\n",
            "Epoch 12/25\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.6077 - loss: 5.1582 - val_accuracy: 0.3333 - val_loss: 5.0088 - learning_rate: 6.0000e-05\n",
            "Epoch 13/25\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.5755 - loss: 4.8828 - val_accuracy: 0.3285 - val_loss: 4.7399 - learning_rate: 6.0000e-05\n",
            "Epoch 14/25\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - accuracy: 0.5686 - loss: 4.6225 - val_accuracy: 0.3237 - val_loss: 4.4860 - learning_rate: 6.0000e-05\n",
            "Epoch 15/25\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.6015 - loss: 4.3617 - val_accuracy: 0.3430 - val_loss: 4.2468 - learning_rate: 6.0000e-05\n",
            "Epoch 16/25\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.6640 - loss: 4.1138 - val_accuracy: 0.3333 - val_loss: 4.0198 - learning_rate: 6.0000e-05\n",
            "Epoch 17/25\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.6687 - loss: 3.8837 - val_accuracy: 0.3333 - val_loss: 3.8028 - learning_rate: 6.0000e-05\n",
            "Epoch 18/25\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - accuracy: 0.7159 - loss: 3.6663 - val_accuracy: 0.3333 - val_loss: 3.5941 - learning_rate: 6.0000e-05\n",
            "Epoch 19/25\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.7640 - loss: 3.4517 - val_accuracy: 0.3237 - val_loss: 3.4014 - learning_rate: 6.0000e-05\n",
            "Epoch 20/25\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2s/step - accuracy: 0.7535 - loss: 3.2533 - val_accuracy: 0.3623 - val_loss: 3.2137 - learning_rate: 6.0000e-05\n",
            "Epoch 21/25\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - accuracy: 0.7737 - loss: 3.0612 - val_accuracy: 0.3816 - val_loss: 3.0331 - learning_rate: 6.0000e-05\n",
            "Epoch 22/25\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.7896 - loss: 2.8823 - val_accuracy: 0.3671 - val_loss: 2.8638 - learning_rate: 6.0000e-05\n",
            "Epoch 23/25\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.8086 - loss: 2.7113 - val_accuracy: 0.3961 - val_loss: 2.6928 - learning_rate: 6.0000e-05\n",
            "Epoch 24/25\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - accuracy: 0.7867 - loss: 2.5553 - val_accuracy: 0.4203 - val_loss: 2.5314 - learning_rate: 6.0000e-05\n",
            "Epoch 25/25\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.7869 - loss: 2.3982 - val_accuracy: 0.4396 - val_loss: 2.3792 - learning_rate: 6.0000e-05\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 435ms/step - accuracy: 0.5027 - loss: 2.3749\n",
            "Final Test Accuracy: 0.4396\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 3s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          AD       0.40      0.68      0.51        69\n",
            "        EMCI       0.77      0.14      0.24        69\n",
            "        LMCI       0.44      0.49      0.47        69\n",
            "\n",
            "    accuracy                           0.44       207\n",
            "   macro avg       0.54      0.44      0.41       207\n",
            "weighted avg       0.54      0.44      0.41       207\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[47  1 21]\n",
            " [37 10 22]\n",
            " [33  2 34]]\n",
            "Accuracy for AD: 68.12%\n",
            "Accuracy for EMCI: 14.49%\n",
            "Accuracy for LMCI: 49.28%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "batch size = 32 , epochs = 50"
      ],
      "metadata": {
        "id": "5JnwDdiVyKH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Set seed for reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Image dimensions and batch size\n",
        "IMG_HEIGHT = 299\n",
        "IMG_WIDTH = 299\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50\n",
        "PATIENCE = 15\n",
        "\n",
        "# Image data generators with augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    brightness_range=[0.6, 1.4]\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Data generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Compute class weights to handle class imbalance\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_generator.classes),\n",
        "    y=train_generator.classes\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# Load EfficientNetB7 model\n",
        "base_model = tf.keras.applications.EfficientNetB7(\n",
        "    weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
        ")\n",
        "\n",
        "# Unfreeze all layers in the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Custom layers on top of EfficientNetB7\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(3, activation='softmax')  # Adjust the number of classes accordingly\n",
        "])\n",
        "\n",
        "# Focal loss implementation\n",
        "def focal_loss(gamma=2., alpha=0.25):\n",
        "    cce = tf.keras.losses.CategoricalCrossentropy()\n",
        "    def loss(y_true, y_pred):\n",
        "        cce_loss = cce(y_true, y_pred)\n",
        "        p_t = tf.reduce_sum(y_true * y_pred, axis=-1)\n",
        "        modulating_factor = tf.pow(1.0 - p_t, gamma)\n",
        "        alpha_weight_factor = tf.reduce_sum(alpha * y_true, axis=-1)\n",
        "        return modulating_factor * alpha_weight_factor * cce_loss\n",
        "    return loss\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=1e-5),  # Adjusted learning rate for fine-tuning\n",
        "    loss=focal_loss(gamma=2., alpha=0.25),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Learning rate scheduler with warm-up\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 5:\n",
        "        return lr + 1e-5\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "# Callbacks\n",
        "lr_reduction = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss', patience=4, factor=0.3, min_lr=1e-6\n",
        ")\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=PATIENCE, restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=test_generator,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[lr_reduction, early_stopping, lr_scheduler],\n",
        "    class_weight=class_weights,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f\"Final Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Predictions and class-wise metrics\n",
        "y_pred = model.predict(test_generator)\n",
        "y_pred_classes = np.argmax(y_pred, axis=-1)\n",
        "y_true = test_generator.classes\n",
        "\n",
        "# Classification Report\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred_classes, target_names=class_labels))\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
        "print(conf_matrix)\n",
        "\n",
        "# Class-wise Accuracy\n",
        "class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
        "for label, acc in zip(class_labels, class_accuracies):\n",
        "    print(f\"Accuracy for {label}: {acc * 100:.2f}%\")\n",
        "\n",
        "# Save the model\n",
        "model.save(\"efficientnetb7_ad_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XbJXZGiPyRUp",
        "outputId": "0be45857-9268-49cf-c4a4-4570eeeabc07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 483 images belonging to 3 classes.\n",
            "Found 207 images belonging to 3 classes.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ efficientnetb7 (\u001b[38;5;33mFunctional\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m2560\u001b[0m)        │      \u001b[38;5;34m64,097,687\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2560\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │       \u001b[38;5;34m1,311,232\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │           \u001b[38;5;34m1,539\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ efficientnetb7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2560</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">64,097,687</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2560</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,311,232</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,539</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m65,410,458\u001b[0m (249.52 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,410,458</span> (249.52 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m65,099,731\u001b[0m (248.34 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,099,731</span> (248.34 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m310,727\u001b[0m (1.19 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">310,727</span> (1.19 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m519s\u001b[0m 14s/step - accuracy: 0.3590 - loss: 8.6126 - val_accuracy: 0.3333 - val_loss: 8.5113 - learning_rate: 2.0000e-05\n",
            "Epoch 2/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 0.3380 - loss: 8.4545 - val_accuracy: 0.3333 - val_loss: 8.2948 - learning_rate: 3.0000e-05\n",
            "Epoch 3/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 2s/step - accuracy: 0.3412 - loss: 8.2152 - val_accuracy: 0.3333 - val_loss: 8.0174 - learning_rate: 4.0000e-05\n",
            "Epoch 4/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.3899 - loss: 7.9303 - val_accuracy: 0.3333 - val_loss: 7.6870 - learning_rate: 5.0000e-05\n",
            "Epoch 5/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.3617 - loss: 7.5778 - val_accuracy: 0.3333 - val_loss: 7.2977 - learning_rate: 6.0000e-05\n",
            "Epoch 6/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2s/step - accuracy: 0.4284 - loss: 7.1805 - val_accuracy: 0.3333 - val_loss: 6.9270 - learning_rate: 6.0000e-05\n",
            "Epoch 7/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.4566 - loss: 6.8174 - val_accuracy: 0.3333 - val_loss: 6.5725 - learning_rate: 6.0000e-05\n",
            "Epoch 8/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - accuracy: 0.5107 - loss: 6.4528 - val_accuracy: 0.3285 - val_loss: 6.2369 - learning_rate: 6.0000e-05\n",
            "Epoch 9/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.5035 - loss: 6.1269 - val_accuracy: 0.3237 - val_loss: 5.9173 - learning_rate: 6.0000e-05\n",
            "Epoch 10/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2s/step - accuracy: 0.4883 - loss: 5.8134 - val_accuracy: 0.3285 - val_loss: 5.6101 - learning_rate: 6.0000e-05\n",
            "Epoch 11/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2s/step - accuracy: 0.5181 - loss: 5.5025 - val_accuracy: 0.2947 - val_loss: 5.3178 - learning_rate: 6.0000e-05\n",
            "Epoch 12/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - accuracy: 0.5601 - loss: 5.2104 - val_accuracy: 0.3188 - val_loss: 5.0392 - learning_rate: 6.0000e-05\n",
            "Epoch 13/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.5670 - loss: 4.9299 - val_accuracy: 0.2850 - val_loss: 4.7736 - learning_rate: 6.0000e-05\n",
            "Epoch 14/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.5879 - loss: 4.6653 - val_accuracy: 0.2947 - val_loss: 4.5202 - learning_rate: 6.0000e-05\n",
            "Epoch 15/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.6297 - loss: 4.4019 - val_accuracy: 0.3043 - val_loss: 4.2796 - learning_rate: 6.0000e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.6475 - loss: 4.1593 - val_accuracy: 0.3333 - val_loss: 4.0514 - learning_rate: 6.0000e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.7363 - loss: 3.9240 - val_accuracy: 0.3188 - val_loss: 3.8341 - learning_rate: 6.0000e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.6927 - loss: 3.7082 - val_accuracy: 0.3430 - val_loss: 3.6257 - learning_rate: 6.0000e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - accuracy: 0.6818 - loss: 3.5027 - val_accuracy: 0.3430 - val_loss: 3.4295 - learning_rate: 6.0000e-05\n",
            "Epoch 20/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - accuracy: 0.7303 - loss: 3.2982 - val_accuracy: 0.3623 - val_loss: 3.2407 - learning_rate: 6.0000e-05\n",
            "Epoch 21/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.7370 - loss: 3.1104 - val_accuracy: 0.3961 - val_loss: 3.0617 - learning_rate: 6.0000e-05\n",
            "Epoch 22/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.7671 - loss: 2.9290 - val_accuracy: 0.3768 - val_loss: 2.8893 - learning_rate: 6.0000e-05\n",
            "Epoch 23/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.7943 - loss: 2.7577 - val_accuracy: 0.3816 - val_loss: 2.7229 - learning_rate: 6.0000e-05\n",
            "Epoch 24/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - accuracy: 0.8094 - loss: 2.5929 - val_accuracy: 0.4251 - val_loss: 2.5677 - learning_rate: 6.0000e-05\n",
            "Epoch 25/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.8739 - loss: 2.4310 - val_accuracy: 0.4444 - val_loss: 2.4155 - learning_rate: 6.0000e-05\n",
            "Epoch 26/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8570 - loss: 2.2852 - val_accuracy: 0.4589 - val_loss: 2.2719 - learning_rate: 6.0000e-05\n",
            "Epoch 27/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8115 - loss: 2.1542 - val_accuracy: 0.4058 - val_loss: 2.1466 - learning_rate: 6.0000e-05\n",
            "Epoch 28/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.8055 - loss: 2.0240 - val_accuracy: 0.4251 - val_loss: 2.0246 - learning_rate: 6.0000e-05\n",
            "Epoch 29/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.8372 - loss: 1.8959 - val_accuracy: 0.4106 - val_loss: 1.9045 - learning_rate: 6.0000e-05\n",
            "Epoch 30/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - accuracy: 0.8380 - loss: 1.7776 - val_accuracy: 0.4348 - val_loss: 1.7857 - learning_rate: 6.0000e-05\n",
            "Epoch 31/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - accuracy: 0.8376 - loss: 1.6706 - val_accuracy: 0.4879 - val_loss: 1.6755 - learning_rate: 6.0000e-05\n",
            "Epoch 32/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2s/step - accuracy: 0.8610 - loss: 1.5631 - val_accuracy: 0.5169 - val_loss: 1.5728 - learning_rate: 6.0000e-05\n",
            "Epoch 33/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.8464 - loss: 1.4706 - val_accuracy: 0.5217 - val_loss: 1.4742 - learning_rate: 6.0000e-05\n",
            "Epoch 34/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8742 - loss: 1.3714"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "batch size = 32 , epochs = 75"
      ],
      "metadata": {
        "id": "ZXflSpj1yRne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Set seed for reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Image dimensions and batch size\n",
        "IMG_HEIGHT = 299\n",
        "IMG_WIDTH = 299\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 75\n",
        "PATIENCE = 15\n",
        "\n",
        "# Image data generators with augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    brightness_range=[0.6, 1.4]\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Data generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Compute class weights to handle class imbalance\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_generator.classes),\n",
        "    y=train_generator.classes\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# Load EfficientNetB7 model\n",
        "base_model = tf.keras.applications.EfficientNetB7(\n",
        "    weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
        ")\n",
        "\n",
        "# Unfreeze all layers in the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Custom layers on top of EfficientNetB7\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(3, activation='softmax')  # Adjust the number of classes accordingly\n",
        "])\n",
        "\n",
        "# Focal loss implementation\n",
        "def focal_loss(gamma=2., alpha=0.25):\n",
        "    cce = tf.keras.losses.CategoricalCrossentropy()\n",
        "    def loss(y_true, y_pred):\n",
        "        cce_loss = cce(y_true, y_pred)\n",
        "        p_t = tf.reduce_sum(y_true * y_pred, axis=-1)\n",
        "        modulating_factor = tf.pow(1.0 - p_t, gamma)\n",
        "        alpha_weight_factor = tf.reduce_sum(alpha * y_true, axis=-1)\n",
        "        return modulating_factor * alpha_weight_factor * cce_loss\n",
        "    return loss\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=1e-5),  # Adjusted learning rate for fine-tuning\n",
        "    loss=focal_loss(gamma=2., alpha=0.25),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Learning rate scheduler with warm-up\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 5:\n",
        "        return lr + 1e-5\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "# Callbacks\n",
        "lr_reduction = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss', patience=4, factor=0.3, min_lr=1e-6\n",
        ")\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=PATIENCE, restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=test_generator,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[lr_reduction, early_stopping, lr_scheduler],\n",
        "    class_weight=class_weights,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f\"Final Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Predictions and class-wise metrics\n",
        "y_pred = model.predict(test_generator)\n",
        "y_pred_classes = np.argmax(y_pred, axis=-1)\n",
        "y_true = test_generator.classes\n",
        "\n",
        "# Classification Report\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred_classes, target_names=class_labels))\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
        "print(conf_matrix)\n",
        "\n",
        "# Class-wise Accuracy\n",
        "class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
        "for label, acc in zip(class_labels, class_accuracies):\n",
        "    print(f\"Accuracy for {label}: {acc * 100:.2f}%\")\n",
        "\n",
        "# Save the model\n",
        "model.save(\"efficientnetb7_ad_model.h5\")\n"
      ],
      "metadata": {
        "id": "BKMaywkUybCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "batch size = 32 , epochs = 100"
      ],
      "metadata": {
        "id": "x9tvnnVGyT9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Set seed for reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Image dimensions and batch size\n",
        "IMG_HEIGHT = 299\n",
        "IMG_WIDTH = 299\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 100\n",
        "PATIENCE = 15\n",
        "\n",
        "# Image data generators with augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    brightness_range=[0.6, 1.4]\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Data generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Compute class weights to handle class imbalance\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_generator.classes),\n",
        "    y=train_generator.classes\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# Load EfficientNetB7 model\n",
        "base_model = tf.keras.applications.EfficientNetB7(\n",
        "    weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
        ")\n",
        "\n",
        "# Unfreeze all layers in the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Custom layers on top of EfficientNetB7\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(3, activation='softmax')  # Adjust the number of classes accordingly\n",
        "])\n",
        "\n",
        "# Focal loss implementation\n",
        "def focal_loss(gamma=2., alpha=0.25):\n",
        "    cce = tf.keras.losses.CategoricalCrossentropy()\n",
        "    def loss(y_true, y_pred):\n",
        "        cce_loss = cce(y_true, y_pred)\n",
        "        p_t = tf.reduce_sum(y_true * y_pred, axis=-1)\n",
        "        modulating_factor = tf.pow(1.0 - p_t, gamma)\n",
        "        alpha_weight_factor = tf.reduce_sum(alpha * y_true, axis=-1)\n",
        "        return modulating_factor * alpha_weight_factor * cce_loss\n",
        "    return loss\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=1e-5),  # Adjusted learning rate for fine-tuning\n",
        "    loss=focal_loss(gamma=2., alpha=0.25),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Learning rate scheduler with warm-up\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 5:\n",
        "        return lr + 1e-5\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "# Callbacks\n",
        "lr_reduction = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss', patience=4, factor=0.3, min_lr=1e-6\n",
        ")\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=PATIENCE, restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=test_generator,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[lr_reduction, early_stopping, lr_scheduler],\n",
        "    class_weight=class_weights,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f\"Final Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Predictions and class-wise metrics\n",
        "y_pred = model.predict(test_generator)\n",
        "y_pred_classes = np.argmax(y_pred, axis=-1)\n",
        "y_true = test_generator.classes\n",
        "\n",
        "# Classification Report\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred_classes, target_names=class_labels))\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
        "print(conf_matrix)\n",
        "\n",
        "# Class-wise Accuracy\n",
        "class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
        "for label, acc in zip(class_labels, class_accuracies):\n",
        "    print(f\"Accuracy for {label}: {acc * 100:.2f}%\")\n",
        "\n",
        "# Save the model\n",
        "model.save(\"efficientnetb7_ad_model.h5\")\n"
      ],
      "metadata": {
        "id": "6dzQyWzEygcX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}